# -*- coding: utf-8 -*-
"""ML_Test_Code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HqsOxvubiftwZ9cJHYVnlwqzgZDkZF4_
"""

#Importing Required Lib
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import pickle

data = pd.read_csv("bike_buyers_clean.csv") #Reading the csv file using pandas
print(data.head(10))    #Printing first ten values of data

"""**Data Analysis**"""

print(data.info())  #printing Infio of data

print(data.dtypes)  #printing datatypes

print(data.isnull().sum())  #To analysis if there are any null values in data

print(data.describe())   #To describe the data

print(data.value_counts())

print(data["Purchased Bike"].value_counts())   #To get the total value count of purchased bike

"""**Data visualization**"""


from sklearn.preprocessing import LabelEncoder    #Importing label encoder to convert catogerical values to numeric

#converting catogerical values to numeric
label_encoder = LabelEncoder() 

data["Marital Status"] = label_encoder.fit_transform(data["Marital Status"])
data["Gender"] = label_encoder.fit_transform(data["Gender"])
data["Education"] = label_encoder.fit_transform(data["Education"])
data["Occupation"] = label_encoder.fit_transform(data["Occupation"])
data["Home Owner"] = label_encoder.fit_transform(data["Home Owner"])
data["Commute Distance"] = label_encoder.fit_transform(data["Commute Distance"])
data["Region"] = label_encoder.fit_transform(data["Region"])
data["Purchased Bike"] = label_encoder.fit_transform(data["Purchased Bike"])
data.head()


"""**Machine Learning Model**"""

data.drop("ID", axis = 1, inplace = True)   #Droping Id since we do nir need it

print(data.head(10))

data.head(10)

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.datasets import make_classification

#Defining Dependent and Independent Variables
X=data.drop(["Purchased Bike"], axis=1)
y=data["Purchased Bike"]

#Split data
X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.30)

#Training the model
model = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=0)
model.fit(X_train, y_train)
pickle.dump(model, open("model.pkl", "wb"))
m = pickle.load(open("model.pkl", "rb"))
#Printing accuracy of the model
score1 = model.score(X_train, y_train)
score2 = model.score(X_test, y_test)


print("Training set accuracy: ", "%.3f"%(score1))
print("Test set accuracy: ", "%.3f"%(score2))

#Comparing Test Data vs Predicted Data
i=0
y_pred=model.predict(X_test)
test_result=list(y_test)
#for i in range(len(y_test)):
for i in range(10):
    print("-----------------------")
    print("Case:", i+1)
    print(y_pred[i])
    print(test_result[i])
    if y_pred[i]==test_result[i]:
        print("Prediction is correct")
    else:
        print("Prediction is incorrect")

#Displaying confusion matrix of the model

from sklearn import metrics
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay


cm = confusion_matrix(y_test, y_pred)
disp=ConfusionMatrixDisplay(confusion_matrix=cm)


disp.plot()
plt.show()

#Statistical Analysis
from sklearn.model_selection import cross_validate
clf = []
clf.append(RandomForestClassifier())

classifier_name = []
mean_value = []
std_value = []

scores = cross_validate(model, X_train, y_train)
print("---------------------------------")
print("Random Forest Classifier")
print("---------------------------------")
    
for key, values in scores.items():
        
    classifier_name.append(clf)
    mean_value.append(values.mean())
    std_value.append(values.std())
        
    print(key," mean ", values.mean())
    print(key," std ", values.std())

#from sklearn.metrics import classification_report
from sklearn.metrics import classification_report
# Printing classification_report
print(classification_report(y_test, y_pred))

